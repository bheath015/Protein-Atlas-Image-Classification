{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIS519Project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bheath015/Protein-Atlas-Image-Classification/blob/peyman/CIS519Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "p3iorOKShYo4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LumfhCpiew11",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# Imports\n",
        "############################################################\n",
        "# Include your imports here, if any are used.\n",
        "\n",
        "!pip install cnn_finetune\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "from google.colab import drive\n",
        "from cnn_finetune import make_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-uWY-vOYSWID",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rwARmJBme0nR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract_data(x_data_filepath, y_data_filepath):\n",
        "    X = np.load(x_data_filepath)\n",
        "    y = np.load(y_data_filepath)\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2bfk1oQvf39L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# Extracting and loading data\n",
        "############################################################\n",
        "class Dataset(Dataset):\n",
        "    \"\"\"CIFAR-10 image dataset.\"\"\"\n",
        "    def __init__(self, X, y, transformations=None, normalize=True):\n",
        "        self.len = len(X) \n",
        "        \n",
        "        # normalize the images\n",
        "        if normalize:\n",
        "            for j in range(X.shape[0]):\n",
        "                X[j,:,:,:] = normalize_image(X[j,:,:,:])\n",
        "            \n",
        "        if torch.cuda.is_available():\n",
        "          self.x_data = torch.from_numpy(X).float().cuda()\n",
        "          self.y_data = torch.from_numpy(y).long().cuda()\n",
        "        else:\n",
        "          self.x_data = torch.from_numpy(X).float()\n",
        "          self.y_data = torch.from_numpy(y).long()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x_data[idx], self.y_data[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUzoAdc4djZ_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# Convolutional Neural Network\n",
        "############################################################\n",
        "class ConvolutionalNN(nn.Module):\n",
        "    \"\"\" \n",
        "        (1) Use self.conv1 as the variable name for your first convolutional layer\n",
        "        (2) Use self.pool as the variable name for your pooling layer\n",
        "        (3) User self.conv2 as the variable name for your second convolutional layer\n",
        "        (4) Use self.fc1 as the variable name for your first fully connected layer\n",
        "        (5) Use self.fc2 as the variable name for your second fully connected layer\n",
        "        (6) Use self.fc3 as the variable name for your third fully connected layer\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \n",
        "        super(ConvolutionalNN, self).__init__()\n",
        "        \n",
        "        # Conv2D: (input channels, output channels, filter size, stride, padding)\n",
        "        self.conv1 = nn.Conv2d(3, 7, 3, 1, 0) \n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(7, 16, 3, 1, 0) \n",
        "\n",
        "        self.fc1 = nn.Linear(16*13*13, 130) \n",
        "        self.fc2 = nn.Linear(130, 72) \n",
        "        self.fc3 = nn.Linear(72, 10) \n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # tensor size (x, y, z, z) <- x: batch size, y: number of channels, z: dimension of each channel\n",
        "        \n",
        "        # out = (64, 7, 30, 30) <- 32x32 input with 3x3 filter: 30x30 output (32-(3-1)=30)  \n",
        "        out = F.relu(self.conv1(x))\n",
        "        \n",
        "        # out = (64, 7, 15, 15) <- 30x30 input with 2x2 filter: 15x15 output (30/2=15)\n",
        "        out = self.pool(out)\n",
        "        \n",
        "        # out = (64, 16, 13, 13) <- 13x13 input with 3x3 filter: 13x13 output (15-(3-1)=13)  \n",
        "        out = F.relu(self.conv2(out))\n",
        "\n",
        "        # 3 fully connected layers (16x13x13 -> 130 -> 72 -> 10)\n",
        "        out = out.view(out.size(0), -1) # flatten each example: out = (64, \") <- batch_size x (16x13x13)\n",
        "        out = F.sigmoid(self.fc1(out))\n",
        "        out = F.sigmoid(self.fc2(out)) \n",
        "        out = F.sigmoid(self.fc3(out))\n",
        "        \n",
        "        return out\n",
        "    \n",
        "    \"\"\" \n",
        "        Please do not change the functions below. \n",
        "        They will be used to test the correctness of your implementation \n",
        "    \"\"\"\n",
        "    def get_conv1_params(self):\n",
        "        return self.conv1.__repr__()\n",
        "    \n",
        "    def get_pool_params(self):\n",
        "        return self.pool.__repr__()\n",
        "\n",
        "    def get_conv2_params(self):\n",
        "        return self.conv2.__repr__()\n",
        "    \n",
        "    def get_fc1_params(self):\n",
        "        return self.fc1.__repr__()\n",
        "    \n",
        "    def get_fc2_params(self):\n",
        "        return self.fc2.__repr__()\n",
        "    \n",
        "    def get_fc3_params(self):\n",
        "        return self.fc3.__repr__()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "paHtQfk8XFaF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def AdvancedCNN(model):\n",
        "    CNN_model = make_model(model, num_classes=27, pretrained=True, input_size=(512,512))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yc0sIBiYdzFd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# Run Experiment\n",
        "############################################################\n",
        "def run_experiment(neural_network, train_loader, test_loader, loss_function, optimizer):\n",
        "    \"\"\"\n",
        "    Runs experiment on the model neural network given a train and test data loader, loss function and optimizer.\n",
        "\n",
        "    Args:\n",
        "        neural_network (NN model that extends torch.nn.Module): For example, it should take an instance of either\n",
        "                                                                FeedForwardNN or ConvolutionalNN,\n",
        "        train_loader (DataLoader),\n",
        "        test_loader (DataLoader),\n",
        "        loss_function (torch.nn.CrossEntropyLoss),\n",
        "        optimizer (optim.SGD)\n",
        "    Returns:\n",
        "        tuple: First position, testing accuracy.\n",
        "               Second position, training accuracy.\n",
        "               Third position, training loss.\n",
        "\n",
        "               For example, if you find that\n",
        "                            testing accuracy = 0.76,\n",
        "                            training accuracy = 0.24\n",
        "                            training loss = 0.56\n",
        "\n",
        "               This function should return (0.76, 0.24, 0.56)\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "       neural_network.cuda()\n",
        "    \n",
        "    max_epochs = 100\n",
        "    train_loss = np.zeros((max_epochs))\n",
        "    train_accuracy = np.zeros((max_epochs))\n",
        "    test_accuracy = np.zeros((max_epochs))\n",
        "    \n",
        "    # optimize weights\n",
        "    for epoch in range(max_epochs):\n",
        "    \n",
        "        print('Training neural network...')\n",
        "        for i, data in enumerate(train_loader, 0):            \n",
        "            train_batch_NN(data, neural_network, loss_function, optimizer) # train on batch\n",
        "\n",
        "        print('Calculating Statistics over Epochs:')\n",
        "        # get training loss and accuracy for this epoch  \n",
        "        train_loss[epoch], train_accuracy[epoch] = get_train_statistics(train_loader, neural_network, loss_function)\n",
        "        test_accuracy[epoch] = get_test_statistics(test_loader, neural_network)\n",
        "        print(\"epoch:\", epoch, \"loss:\", train_loss[epoch], \"train accuracy:\", train_accuracy[epoch], \"test accuracy:\", \n",
        "              test_accuracy[epoch])\n",
        "        \n",
        "    return (train_loss, train_accuracy, test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MYaxaZWresbx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize_image(image):\n",
        "    \"\"\"\n",
        "    Normalizes the RGB pixel values of an image.\n",
        "\n",
        "    Args:\n",
        "        image (3D NumPy array): For example, it should take in a single 3x32x32 image from the CIFAR-10 dataset\n",
        "    Returns:\n",
        "        tuple: The normalized image\n",
        "    \"\"\"\n",
        "    mean = np.mean(image, axis=(1,2))\n",
        "    std = np.std(image, axis=(1,2))\n",
        "    normalized_image = ((image[0,:,:] - mean[0]) / std[0], \n",
        "                        (image[1,:,:] - mean[1]) / std[1], \n",
        "                        (image[2,:,:] - mean[2]) / std[2])\n",
        "    return np.stack(normalized_image, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M6T8PTvWe8uy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# REQUIRED METHOD - Function to train a single batch in the NN (used in run_experiment())\n",
        "\n",
        "def train_batch_NN(data, neural_network, loss_function, optimizer):\n",
        "\n",
        "    # Get inputs and labels from data loader \n",
        "    inputs, labels = data\n",
        "\n",
        "    #print(inputs.size())\n",
        "    inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      inputs.cuda()\n",
        "      labels.cuda()\n",
        "\n",
        "\n",
        "    # Feed the input data into the network \n",
        "    y_pred = neural_network(inputs)\n",
        "\n",
        "\n",
        "    # Calculate the loss using predicted labels and ground truth labels\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss = loss_function(y_pred, labels)\n",
        "\n",
        "\n",
        "    # backpropogates to compute gradient\n",
        "    loss.backward()\n",
        "\n",
        "    # updates the weghts\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2yrc0ynafCIv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# REQUIRED METHOD - Function to get loss and accuracy across all training examples in the NN (used in run_experiment())\n",
        "\n",
        "def get_train_statistics(train_loader, neural_network, loss_function):\n",
        "    \n",
        "    correct = 0\n",
        "    sum_loss = 0\n",
        "    \n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "          \n",
        "            # Get inputs and labels from data loader \n",
        "            inputs, labels = data\n",
        "            \n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "            \n",
        "            if torch.cuda.is_available():\n",
        "              inputs.cuda()\n",
        "              labels.cuda()\n",
        "            \n",
        "        \n",
        "            # Feed the input data into the network \n",
        "            y_pred = neural_network(inputs)\n",
        "            \n",
        "            # Calculate the loss using predicted labels and ground truth labels\n",
        "            loss = loss_function(y_pred, labels)\n",
        "\n",
        "            \n",
        "            # convert predicted labels into numpy\n",
        "            nploss= loss.cpu().data.numpy()\n",
        "            sum_loss = sum_loss + nploss\n",
        "            \n",
        "            \n",
        "            y_pred_np = y_pred.cpu().data.numpy()\n",
        "            label_np = labels.cpu().data.numpy().reshape(len(labels),1)\n",
        "            \n",
        "              \n",
        "            pred_np = np.argmax(y_pred_np, axis=1)\n",
        "            \n",
        "            for j in range(y_pred_np.shape[0]):\n",
        "                if pred_np[j] == label_np[j]:\n",
        "                    correct += 1\n",
        "    \n",
        "    # calculate the accuracy across batches\n",
        "    train_accuracy = float(correct)/float(len(train_loader.dataset))\n",
        "    \n",
        "    return sum_loss, train_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ULpwmUC4fFfE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# REQUIRED METHOD - Function to accuracy across all test examples in the NN (used in run_experiment())\n",
        "\n",
        "def get_test_statistics(test_loader, neural_network):\n",
        "    \n",
        "    correct_test = 0\n",
        "    \n",
        "    for i, data in enumerate(test_loader, 0):\n",
        "\n",
        "            # Get inputs and labels from data loader \n",
        "            inputs, labels = data\n",
        "\n",
        "            #print(inputs.size())\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "            \n",
        "            if torch.cuda.is_available():\n",
        "              inputs.cuda()\n",
        "              labels.cuda()\n",
        "\n",
        "\n",
        "            # Feed the input data into the network \n",
        "            y_pred_test = neural_network(inputs)\n",
        "\n",
        "\n",
        "            # convert predicted laels into numpy\n",
        "            y_pred_np_test = y_pred_test.cpu().data.numpy()\n",
        "            label_np_test = labels.cpu().data.numpy().reshape(len(labels),1)\n",
        "           \n",
        "          \n",
        "            # calculate the training accuracy of the current model\n",
        "            pred_np_test = np.argmax(y_pred_np_test, axis=1)\n",
        "\n",
        "\n",
        "            for j in range(y_pred_np_test.shape[0]):\n",
        "                if pred_np_test[j] == label_np_test[j]:\n",
        "                    correct_test += 1\n",
        "    \n",
        "    # calculate the accuracy across batches\n",
        "    test_accuracy = float(total_correct) / float(len(test_loader.dataset))\n",
        "    \n",
        "    return test_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BbMZi746fIeA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function to plot the loss and training accuracy over epochs\n",
        "\n",
        "def plot_epoch_stats(loss, train_accuracy, test_accuracy):\n",
        "    \n",
        "    max_epochs = 100\n",
        "    print(\"final training accuracy: \", train_accuracy[max_epochs-1])\n",
        "    print(\"final test accuracy: \", test_accuracy[max_epochs-1])\n",
        "    epoch_number = np.arange(0,max_epochs,1)\n",
        "\n",
        "    # Plot the loss over epoch\n",
        "    plt.figure()\n",
        "    plt.plot(epoch_number, loss)\n",
        "    plt.title('Total Loss over Epochs')\n",
        "    plt.xlabel('Number of Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    # Plot the training accuracy over epoch\n",
        "    plt.figure()\n",
        "    plt.plot(epoch_number, train_accuracy)\n",
        "    plt.title('Training Accuracy over Epochs')\n",
        "    plt.xlabel('Number of Epochs')\n",
        "    plt.ylabel('accuracy')\n",
        "    \n",
        "    # Plot the testing accuracy over epoch\n",
        "    plt.figure()\n",
        "    plt.plot(epoch_number, test_accuracy)\n",
        "    plt.title('Testing Accuracy over Epochs')\n",
        "    plt.xlabel('Number of Epochs')\n",
        "    plt.ylabel('accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6upZfsfHfY6S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# RUN CODE BELOW HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "33qJ3E7Or5Tc",
        "colab_type": "code",
        "outputId": "581aaead-4b92-499c-fc23-04085ef0523c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "label_dict = {\n",
        "    0:  \"Nucleoplasm\",  \n",
        "    1:  \"Nuclear membrane\",   \n",
        "    2:  \"Nucleoli\",   \n",
        "    3:  \"Nucleoli fibrillar center\",   \n",
        "    4:  \"Nuclear speckles\",\n",
        "    5:  \"Nuclear bodies\",   \n",
        "    6:  \"Endoplasmic reticulum\",   \n",
        "    7:  \"Golgi apparatus\",   \n",
        "    8:  \"Peroxisomes\",   \n",
        "    9:  \"Endosomes\",   \n",
        "    10:  \"Lysosomes\",   \n",
        "    11:  \"Intermediate filaments\",   \n",
        "    12:  \"Actin filaments\",   \n",
        "    13:  \"Focal adhesion sites\",   \n",
        "    14:  \"Microtubules\",   \n",
        "    15:  \"Microtubule ends\",   \n",
        "    16:  \"Cytokinetic bridge\",   \n",
        "    17:  \"Mitotic spindle\",   \n",
        "    18:  \"Microtubule organizing center\",   \n",
        "    19:  \"Centrosome\",   \n",
        "    20:  \"Lipid droplets\",   \n",
        "    21:  \"Plasma membrane\",   \n",
        "    22:  \"Cell junctions\",   \n",
        "    23:  \"Mitochondria\",   \n",
        "    24:  \"Aggresome\",   \n",
        "    25:  \"Cytosol\",   \n",
        "    26:  \"Cytoplasmic bodies\",   \n",
        "    27:  \"Rods & rings\"\n",
        "}\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "train_labels_file_path = '/content/gdrive/My Drive/Colab Notebooks/train.csv'\n",
        "\n",
        "with open(train_labels_file_path) as train_labels_file:\n",
        "    labels_df = pd.read_csv(train_labels_file)\n",
        "    \n",
        "print(labels_df)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-83c132dc842a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mtrain_labels_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/My Drive/Colab Notebooks/train.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels_file_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrain_labels_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mlabels_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/Colab Notebooks/train.csv'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "GlGMmUOBfdwt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialize constants\n",
        "\n",
        "train_images_file_path = '/content/gdrive/My Drive/Colab Notebooks/train'\n",
        "test_images_file_path = '/content/gdrive/My Drive/Colab Notebooks/test'\n",
        "test_labels_file_path = '/content/gdrive/My Drive/Colab Notebooks/cifar10-data/test_labels.npy'\n",
        "\n",
        "# create train and test data loaders\n",
        "X_train, y_train = extract_data('gdrive/My Drive/?.npy', 'gdrive/My Drive/?.npy') # ? examples ################################ GPU\n",
        "X_test, y_test = extract_data('gdrive/My Drive/?.npy', 'gdrive/My Drive/?.npy') # ? examples ################################ GPU\n",
        "\n",
        "# specify the loss function\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "if torch.cuda.is_available():\n",
        "   loss_function.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LQBFjTeEfveA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run Experiment and save results\n",
        "\n",
        "train_dataset = Dataset(X_train, y_train, normalize=False)\n",
        "test_dataset = Dataset(X_test, y_test, normalize=False)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "conv_raw_net = ConvolutionalNN() # create the NN\n",
        "optimizer = optim.SGD(conv_raw_net.parameters(), lr=0.001, momentum=0.9) # specify the optimizer\n",
        "(loss, train_accuracy, test_accuracy) = run_experiment(conv_raw_net, train_loader, test_loader, loss_function, optimizer)\n",
        "\n",
        "# np.save(\"gdrive/My Drive/statistics/conv_loss.npy\", loss)\n",
        "# np.save(\"gdrive/My Drive/statistics/conv_train_accuracy.npy\", train_accuracy)\n",
        "# np.save(\"gdrive/My Drive/statistics/conv_test_accuracy.npy\", test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nQtZjyOqYtbo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run Experiment on Advanced CNN:\n",
        "\n",
        "# get the name of model here https://pypi.org/project/cnn-finetune/\n",
        "\n",
        "name = 'resnet18'\n",
        "CNN_Model = AdvancedCNN(name)\n",
        "optimizer = optim.SGD(CNN_Model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "(loss, train_accuracy, test_accuracy) = run_experiment(CNN_Model, train_loader, test_loader, loss_function, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}