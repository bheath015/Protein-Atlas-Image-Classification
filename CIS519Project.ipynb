{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIS519Project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bheath015/Protein-Atlas-Image-Classification/blob/brian/CIS519Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "p3iorOKShYo4",
        "colab_type": "code",
        "outputId": "8c873275-c33f-41c1-ba35-83d8c41b652d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x57da6000 @  0x7f1a03ba92a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LumfhCpiew11",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# Imports\n",
        "############################################################\n",
        "# Include your imports here, if any are used.\n",
        "\n",
        "!pip install cnn_finetune\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "from google.colab import drive\n",
        "from cnn_finetune import make_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rwARmJBme0nR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract_data(x_data_filepath, y_data_filepath):\n",
        "    X = np.load(x_data_filepath)\n",
        "    y = np.load(y_data_filepath)\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2bfk1oQvf39L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# Extracting and loading data\n",
        "############################################################\n",
        "class Dataset(Dataset):\n",
        "    \"\"\"CIFAR-10 image dataset.\"\"\"\n",
        "    def __init__(self, X, y, transformations=None, normalize=True):\n",
        "        self.len = len(X) \n",
        "        \n",
        "        # normalize the images\n",
        "        if normalize:\n",
        "            for j in range(X.shape[0]):\n",
        "                X[j,:,:,:] = normalize_image(X[j,:,:,:])\n",
        "            \n",
        "        if torch.cuda.is_available():\n",
        "          self.x_data = torch.from_numpy(X).float().cuda()\n",
        "          self.y_data = torch.from_numpy(y).long().cuda()\n",
        "        else:\n",
        "          self.x_data = torch.from_numpy(X).float()\n",
        "          self.y_data = torch.from_numpy(y).long()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x_data[idx], self.y_data[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUzoAdc4djZ_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# Convolutional Neural Network\n",
        "############################################################\n",
        "class ConvolutionalNN(nn.Module):\n",
        "    \"\"\" \n",
        "        (1) Use self.conv1 as the variable name for your first convolutional layer\n",
        "        (2) Use self.pool as the variable name for your pooling layer\n",
        "        (3) User self.conv2 as the variable name for your second convolutional layer\n",
        "        (4) Use self.fc1 as the variable name for your first fully connected layer\n",
        "        (5) Use self.fc2 as the variable name for your second fully connected layer\n",
        "        (6) Use self.fc3 as the variable name for your third fully connected layer\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \n",
        "        super(ConvolutionalNN, self).__init__()\n",
        "        \n",
        "        # Conv2D: (input channels, output channels, filter size, stride, padding)\n",
        "        self.conv1 = nn.Conv2d(3, 7, 3, 1, 0) \n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(7, 16, 3, 1, 0) \n",
        "\n",
        "        self.fc1 = nn.Linear(16*13*13, 130) \n",
        "        self.fc2 = nn.Linear(130, 72) \n",
        "        self.fc3 = nn.Linear(72, 10) \n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # tensor size (x, y, z, z) <- x: batch size, y: number of channels, z: dimension of each channel\n",
        "        \n",
        "        # out = (64, 7, 30, 30) <- 32x32 input with 3x3 filter: 30x30 output (32-(3-1)=30)  \n",
        "        out = F.relu(self.conv1(x))\n",
        "        \n",
        "        # out = (64, 7, 15, 15) <- 30x30 input with 2x2 filter: 15x15 output (30/2=15)\n",
        "        out = self.pool(out)\n",
        "        \n",
        "        # out = (64, 16, 13, 13) <- 13x13 input with 3x3 filter: 13x13 output (15-(3-1)=13)  \n",
        "        out = F.relu(self.conv2(out))\n",
        "\n",
        "        # 3 fully connected layers (16x13x13 -> 130 -> 72 -> 10)\n",
        "        out = out.view(out.size(0), -1) # flatten each example: out = (64, \") <- batch_size x (16x13x13)\n",
        "        out = F.sigmoid(self.fc1(out))\n",
        "        out = F.sigmoid(self.fc2(out)) \n",
        "        out = F.sigmoid(self.fc3(out))\n",
        "        \n",
        "        return out\n",
        "    \n",
        "    \"\"\" \n",
        "        Please do not change the functions below. \n",
        "        They will be used to test the correctness of your implementation \n",
        "    \"\"\"\n",
        "    def get_conv1_params(self):\n",
        "        return self.conv1.__repr__()\n",
        "    \n",
        "    def get_pool_params(self):\n",
        "        return self.pool.__repr__()\n",
        "\n",
        "    def get_conv2_params(self):\n",
        "        return self.conv2.__repr__()\n",
        "    \n",
        "    def get_fc1_params(self):\n",
        "        return self.fc1.__repr__()\n",
        "    \n",
        "    def get_fc2_params(self):\n",
        "        return self.fc2.__repr__()\n",
        "    \n",
        "    def get_fc3_params(self):\n",
        "        return self.fc3.__repr__()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "paHtQfk8XFaF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def AdvancedCNN(model,num_classes=27,input_size=(512,512)):\n",
        "    CNN_model = make_model(model, num_classes=num_classes, pretrained=True, input_size=input_size)\n",
        "    \n",
        "    return CNN_model\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yc0sIBiYdzFd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "############################################################\n",
        "# Run Experiment\n",
        "############################################################\n",
        "def run_experiment(neural_network, train_loader, test_loader, loss_function, optimizer):\n",
        "    \"\"\"\n",
        "    Runs experiment on the model neural network given a train and test data loader, loss function and optimizer.\n",
        "\n",
        "    Args:\n",
        "        neural_network (NN model that extends torch.nn.Module): For example, it should take an instance of either\n",
        "                                                                FeedForwardNN or ConvolutionalNN,\n",
        "        train_loader (DataLoader),\n",
        "        test_loader (DataLoader),\n",
        "        loss_function (torch.nn.CrossEntropyLoss),\n",
        "        optimizer (optim.SGD)\n",
        "    Returns:\n",
        "        tuple: First position, testing accuracy.\n",
        "               Second position, training accuracy.\n",
        "               Third position, training loss.\n",
        "\n",
        "               For example, if you find that\n",
        "                            testing accuracy = 0.76,\n",
        "                            training accuracy = 0.24\n",
        "                            training loss = 0.56\n",
        "\n",
        "               This function should return (0.76, 0.24, 0.56)\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "       neural_network.cuda()\n",
        "    \n",
        "    max_epochs = 100\n",
        "    train_loss = np.zeros((max_epochs))\n",
        "    train_accuracy = np.zeros((max_epochs))\n",
        "    test_accuracy = np.zeros((max_epochs))\n",
        "    \n",
        "    # optimize weights\n",
        "    for epoch in range(max_epochs):\n",
        "    \n",
        "        print('Training neural network...')\n",
        "        for i, data in enumerate(train_loader, 0):            \n",
        "            train_batch_NN(data, neural_network, loss_function, optimizer) # train on batch\n",
        "\n",
        "        print('Calculating Statistics over Epochs:')\n",
        "        # get training loss and accuracy for this epoch  \n",
        "        train_loss[epoch], train_accuracy[epoch] = get_train_statistics(train_loader, neural_network, loss_function)\n",
        "        test_accuracy[epoch] = get_test_statistics(test_loader, neural_network)\n",
        "        print(\"epoch:\", epoch, \"loss:\", train_loss[epoch], \"train accuracy:\", train_accuracy[epoch], \"test accuracy:\", \n",
        "              test_accuracy[epoch])\n",
        "        \n",
        "    return (train_loss, train_accuracy, test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MYaxaZWresbx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize_image(image):\n",
        "    \"\"\"\n",
        "    Normalizes the RGB pixel values of an image.\n",
        "\n",
        "    Args:\n",
        "        image (3D NumPy array): For example, it should take in a single 3x32x32 image from the CIFAR-10 dataset\n",
        "    Returns:\n",
        "        tuple: The normalized image\n",
        "    \"\"\"\n",
        "    mean = np.mean(image, axis=(1,2))\n",
        "    std = np.std(image, axis=(1,2))\n",
        "    normalized_image = ((image[0,:,:] - mean[0]) / std[0], \n",
        "                        (image[1,:,:] - mean[1]) / std[1], \n",
        "                        (image[2,:,:] - mean[2]) / std[2])\n",
        "    return np.stack(normalized_image, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M6T8PTvWe8uy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# REQUIRED METHOD - Function to train a single batch in the NN (used in run_experiment())\n",
        "\n",
        "def train_batch_NN(data, neural_network, loss_function, optimizer):\n",
        "\n",
        "    # Get inputs and labels from data loader \n",
        "    inputs, labels = data\n",
        "\n",
        "    #print(inputs.size())\n",
        "    inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      inputs.cuda()\n",
        "      labels.cuda()\n",
        "\n",
        "\n",
        "    # Feed the input data into the network \n",
        "    y_pred = neural_network(inputs)\n",
        "\n",
        "\n",
        "    # Calculate the loss using predicted labels and ground truth labels\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss = loss_function(y_pred, labels)\n",
        "\n",
        "\n",
        "    # backpropogates to compute gradient\n",
        "    loss.backward()\n",
        "\n",
        "    # updates the weghts\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2yrc0ynafCIv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# REQUIRED METHOD - Function to get loss and accuracy across all training examples in the NN (used in run_experiment())\n",
        "\n",
        "def get_train_statistics(train_loader, neural_network, loss_function):\n",
        "    \n",
        "    correct = 0\n",
        "    sum_loss = 0\n",
        "    \n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "          \n",
        "            # Get inputs and labels from data loader \n",
        "            inputs, labels = data\n",
        "            \n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "            \n",
        "            if torch.cuda.is_available():\n",
        "              inputs.cuda()\n",
        "              labels.cuda()\n",
        "            \n",
        "        \n",
        "            # Feed the input data into the network \n",
        "            y_pred = neural_network(inputs)\n",
        "            \n",
        "            # Calculate the loss using predicted labels and ground truth labels\n",
        "            loss = loss_function(y_pred, labels)\n",
        "\n",
        "            \n",
        "            # convert predicted labels into numpy\n",
        "            nploss= loss.cpu().data.numpy()\n",
        "            sum_loss = sum_loss + nploss\n",
        "            \n",
        "            \n",
        "            y_pred_np = y_pred.cpu().data.numpy()\n",
        "            label_np = labels.cpu().data.numpy().reshape(len(labels),1)\n",
        "            \n",
        "              \n",
        "            pred_np = np.argmax(y_pred_np, axis=1)\n",
        "            \n",
        "            for j in range(y_pred_np.shape[0]):\n",
        "                if pred_np[j] == label_np[j]:\n",
        "                    correct += 1\n",
        "    \n",
        "    # calculate the accuracy across batches\n",
        "    train_accuracy = float(correct)/float(len(train_loader.dataset))\n",
        "    \n",
        "    return sum_loss, train_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ULpwmUC4fFfE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# REQUIRED METHOD - Function to accuracy across all test examples in the NN (used in run_experiment())\n",
        "\n",
        "def get_test_statistics(test_loader, neural_network):\n",
        "    \n",
        "    correct_test = 0\n",
        "    \n",
        "    for i, data in enumerate(test_loader, 0):\n",
        "\n",
        "            # Get inputs and labels from data loader \n",
        "            inputs, labels = data\n",
        "\n",
        "            #print(inputs.size())\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "            \n",
        "            if torch.cuda.is_available():\n",
        "              inputs.cuda()\n",
        "              labels.cuda()\n",
        "\n",
        "\n",
        "            # Feed the input data into the network \n",
        "            y_pred_test = neural_network(inputs)\n",
        "\n",
        "\n",
        "            # convert predicted laels into numpy\n",
        "            y_pred_np_test = y_pred_test.cpu().data.numpy()\n",
        "            label_np_test = labels.cpu().data.numpy().reshape(len(labels),1)\n",
        "           \n",
        "          \n",
        "            # calculate the training accuracy of the current model\n",
        "            pred_np_test = np.argmax(y_pred_np_test, axis=1)\n",
        "\n",
        "\n",
        "            for j in range(y_pred_np_test.shape[0]):\n",
        "                if pred_np_test[j] == label_np_test[j]:\n",
        "                    correct_test += 1\n",
        "    \n",
        "    # calculate the accuracy across batches\n",
        "    test_accuracy = float(total_correct) / float(len(test_loader.dataset))\n",
        "    \n",
        "    return test_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BbMZi746fIeA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function to plot the loss and training accuracy over epochs\n",
        "\n",
        "def plot_epoch_stats(loss, train_accuracy, test_accuracy):\n",
        "    \n",
        "    max_epochs = 100\n",
        "    print(\"final training accuracy: \", train_accuracy[max_epochs-1])\n",
        "    print(\"final test accuracy: \", test_accuracy[max_epochs-1])\n",
        "    epoch_number = np.arange(0,max_epochs,1)\n",
        "\n",
        "    # Plot the loss over epoch\n",
        "    plt.figure()\n",
        "    plt.plot(epoch_number, loss)\n",
        "    plt.title('Total Loss over Epochs')\n",
        "    plt.xlabel('Number of Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    # Plot the training accuracy over epoch\n",
        "    plt.figure()\n",
        "    plt.plot(epoch_number, train_accuracy)\n",
        "    plt.title('Training Accuracy over Epochs')\n",
        "    plt.xlabel('Number of Epochs')\n",
        "    plt.ylabel('accuracy')\n",
        "    \n",
        "    # Plot the testing accuracy over epoch\n",
        "    plt.figure()\n",
        "    plt.plot(epoch_number, test_accuracy)\n",
        "    plt.title('Testing Accuracy over Epochs')\n",
        "    plt.xlabel('Number of Epochs')\n",
        "    plt.ylabel('accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6upZfsfHfY6S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# RUN CODE BELOW HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ah79C1O5wh18",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# function to load all images in directory as numpy array\n",
        "\n",
        "def data_to_numpy(directory_name, num_images=None):\n",
        "  '''\n",
        "  Construct a num_imagesxwidthxheight numpy array of \n",
        "\n",
        "  :param directory_name: name of the directory where the dataset is stored\n",
        "  :param num_images: number of images to keep in resulting 4D numpy array\n",
        "                     if None, use all images\n",
        "  :return: numpy array of images: (num_images, 4 color channels, width, height)\n",
        "  '''\n",
        "  \n",
        "  channel_colors = ['red', 'blue', 'green', 'yellow']\n",
        "  \n",
        "  # make a list of all 4-channel images in directory (red, blue, green, yellow)\n",
        "  image_names = list({image_name.split('_')[0] \n",
        "                      for image_name in os.listdir(directory_name) if image_name.split('.')[-1] == 'png'})\n",
        "  random.shuffle(image_names) # shuffle images\n",
        "    \n",
        "  # if num_images is None, set to use ALL images in directory\n",
        "  if num_images == None:\n",
        "    num_images = len(image_names)\n",
        "  \n",
        "  # put 4-channel images into 4D numpy array\n",
        "  images = []\n",
        "  \n",
        "  count = 0\n",
        "  num_used = 0\n",
        "  while num_used < num_images and count < len(image_names):\n",
        "    \n",
        "    image_name = image_names[count]\n",
        "    count += 1\n",
        "      \n",
        "    # create a list of all the channels in the image \n",
        "    channels = [cv2.imread(directory_name + '/' + image_name + '_' + color + \n",
        "                           '.png', 0) for color in channel_colors]\n",
        "\n",
        "    # check if any of the channels are missing for image\n",
        "    missing_channels = [x is None for x in channels]\n",
        "    \n",
        "    # add 3D image to list if no channels are missing\n",
        "    if any(missing_channels):\n",
        "      print('skipped', image_name + ', missing',  ###### COMMENT THIS OUT\n",
        "            [channel_colors[i] for i, x in enumerate(channels) if x is None])\n",
        "      continue\n",
        "    else:\n",
        "#       print('used', image_name) ###### COMMENT THIS OUT\n",
        "      num_used += 1\n",
        "      images.append(np.stack(channels, axis=0))\n",
        "  \n",
        "  # stack 3D images into 4D numpy array\n",
        "  print('skipped', count - num_used, 'images due to missing channels')\n",
        "  return np.stack(images, axis=0), image_names\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QXISsghKLsng",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "\n",
        "filename = \"/content/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LvIU5TsTNPj9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp /content/.kaggle/kaggle.json /root/.kaggle/kaggle.json\n",
        "!kaggle competitions list\n",
        "!kaggle competitions download  -c human-protein-atlas-image-classification -p /content/kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vSgv9fILuZBW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir '/content/kaggle/train'\n",
        "!mkdir '/content/kaggle/test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pbfK5Gu-tFZ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cd '/content/kaggle/test'\n",
        "!unzip -q /content/kaggle/test.zip\n",
        "from IPython.display import Image\n",
        "Image(filename='/content/kaggle/test/a142c680-bacb-11e8-b2b8-ac1f6b6435d0_green.png') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EhrbniX9vZaD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files_in_content = os.listdir('/content')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "midbJixDu6wK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cd '/content/kaggle/train'\n",
        "!unzip -q /content/kaggle/train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yzJtw6CsySek",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sqJXk0utTgqX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_files = None\n",
        "[x_test, test_images] = data_to_numpy('/content', num_files)\n",
        "print(x_test.shape)\n",
        "np.save(\"/content/kaggle/test/X_test.npy\", x_test)\n",
        "np.save(\"/content/kaggle/test/test_images\", test_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lqmcRiV0308t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.listdir('/content')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IO9VI5o7zsHF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(x_test[0][0])\n",
        "plt.imshow(x_test[0][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QbNV2dm21dTG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_files = None\n",
        "[x_train, train_images] = data_to_numpy('/content', num_files)\n",
        "print(x_train.shape)\n",
        "np.save(\"/content/kaggle/train/X_test.npy\", x_train)\n",
        "np.save(\"/content/kaggle/train/test_images\", train_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EMu4p3EAUAeu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(filename='/content/a142c680-bacb-11e8-b2b8-ac1f6b6435d0_green.png') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "33qJ3E7Or5Tc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import pandas as pd\n",
        "\n",
        "label_dict = {\n",
        "    0:  \"Nucleoplasm\",  \n",
        "    1:  \"Nuclear membrane\",   \n",
        "    2:  \"Nucleoli\",   \n",
        "    3:  \"Nucleoli fibrillar center\",   \n",
        "    4:  \"Nuclear speckles\",\n",
        "    5:  \"Nuclear bodies\",   \n",
        "    6:  \"Endoplasmic reticulum\",   \n",
        "    7:  \"Golgi apparatus\",   \n",
        "    8:  \"Peroxisomes\",   \n",
        "    9:  \"Endosomes\",   \n",
        "    10:  \"Lysosomes\",   \n",
        "    11:  \"Intermediate filaments\",   \n",
        "    12:  \"Actin filaments\",   \n",
        "    13:  \"Focal adhesion sites\",   \n",
        "    14:  \"Microtubules\",   \n",
        "    15:  \"Microtubule ends\",   \n",
        "    16:  \"Cytokinetic bridge\",   \n",
        "    17:  \"Mitotic spindle\",   \n",
        "    18:  \"Microtubule organizing center\",   \n",
        "    19:  \"Centrosome\",   \n",
        "    20:  \"Lipid droplets\",   \n",
        "    21:  \"Plasma membrane\",   \n",
        "    22:  \"Cell junctions\",   \n",
        "    23:  \"Mitochondria\",   \n",
        "    24:  \"Aggresome\",   \n",
        "    25:  \"Cytosol\",   \n",
        "    26:  \"Cytoplasmic bodies\",   \n",
        "    27:  \"Rods & rings\"\n",
        "}\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "train_labels_file_path = '/content/kaggle/train.csv'\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "with open(train_labels_file_path) as train_labels_file:\n",
        "    labels_df = pd.read_csv(train_labels_file)\n",
        "\n",
        "rows = labels_df.shape[0]\n",
        "for i in range(rows):\n",
        "    labels_df['Target'][i] = labels_df['Target'][i].split(' ')\n",
        "\n",
        "out = pd.DataFrame(mlb.fit_transform(labels_df['Target']), columns=mlb.classes_, index=labels_df.index)\n",
        "print(out)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GlGMmUOBfdwt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialize constants\n",
        "'''\n",
        "train_images_file_path = '/content/gdrive/My Drive/Colab Notebooks/train'\n",
        "test_images_file_path = '/content/gdrive/My Drive/Colab Notebooks/test'\n",
        "test_labels_file_path = '/content/gdrive/My Drive/Colab Notebooks/cifar10-data/test_labels.npy'\n",
        "\n",
        "# create train and test data loaders\n",
        "X_train, y_train = extract_data('gdrive/My Drive/?.npy', 'gdrive/My Drive/?.npy') # ? examples ################################ GPU\n",
        "X_test, y_test = extract_data('gdrive/My Drive/?.npy', 'gdrive/My Drive/?.npy') # ? examples ################################ GPU\n",
        "'''\n",
        "# specify the loss function\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "if torch.cuda.is_available():\n",
        "   loss_function.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qbwVA0iWcWvU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#test\n",
        "x_train = 'drive/My Drive/COLAB/CIS 519/HW3/cifar10-data/train_images.npy'\n",
        "y_train = 'drive/My Drive/COLAB/CIS 519/HW3/cifar10-data/train_labels.npy'\n",
        "X_train,y_train = extract_data(x_train,y_train)\n",
        "\n",
        "\n",
        "  \n",
        "x_test = 'drive/My Drive/COLAB/CIS 519/HW3/cifar10-data/test_images.npy'\n",
        "y_test= 'drive/My Drive/COLAB/CIS 519/HW3/cifar10-data/test_labels.npy'\n",
        "X_test, y_test = extract_data(x_test,y_test)\n",
        "\n",
        "train_dataset = Dataset(X_train, y_train, normalize=False)\n",
        "test_dataset = Dataset(X_test, y_test, normalize=False)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LQBFjTeEfveA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run Experiment and save results\n",
        "\n",
        "train_dataset = Dataset(X_train, y_train, normalize=False)\n",
        "test_dataset = Dataset(X_test, y_test, normalize=False)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "conv_raw_net = ConvolutionalNN() # create the NN\n",
        "optimizer = optim.SGD(conv_raw_net.parameters(), lr=0.001, momentum=0.9) # specify the optimizer\n",
        "(loss, train_accuracy, test_accuracy) = run_experiment(conv_raw_net, train_loader, test_loader, loss_function, optimizer)\n",
        "\n",
        "# np.save(\"gdrive/My Drive/statistics/conv_loss.npy\", loss)\n",
        "# np.save(\"gdrive/My Drive/statistics/conv_train_accuracy.npy\", train_accuracy)\n",
        "# np.save(\"gdrive/My Drive/statistics/conv_test_accuracy.npy\", test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nQtZjyOqYtbo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run Experiment on Advanced CNN:\n",
        "\n",
        "# get the name of model here https://pypi.org/project/cnn-finetune/\n",
        "\n",
        "name = 'resnet18'\n",
        "CNN_Model = AdvancedCNN(name)\n",
        "optimizer = optim.SGD(CNN_Model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "(loss, train_accuracy, test_accuracy) = run_experiment(CNN_Model, train_loader, test_loader, loss_function, optimizer)\n",
        "plot_epoch_stats(loss, train_accuracy, test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}