{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIS519Project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bheath015/Protein-Atlas-Image-Classification/blob/master/CIS519Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "p3iorOKShYo4",
        "colab_type": "code",
        "outputId": "8c873275-c33f-41c1-ba35-83d8c41b652d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x57da6000 @  0x7f1a03ba92a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LumfhCpiew11",
        "colab_type": "code",
        "outputId": "441cb6f3-f545-4bee-fd4c-e6e79fd0e75c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# Imports\n",
        "############################################################\n",
        "# Include your imports here, if any are used.\n",
        "\n",
        "!pip install cnn_finetune\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "from google.colab import drive\n",
        "from cnn_finetune import make_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cnn_finetune\n",
            "  Downloading https://files.pythonhosted.org/packages/21/c7/97f7056e0e82f3d25cb9049b133394d52ac3008be6887d3894b23465e7b3/cnn_finetune-0.5.1.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from cnn_finetune) (0.4.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from cnn_finetune) (0.2.1)\n",
            "Collecting pretrainedmodels (from cnn_finetune)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cnn_finetune) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from cnn_finetune) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision->cnn_finetune) (1.14.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->cnn_finetune) (5.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->cnn_finetune) (1.11.0)\n",
            "Collecting munch (from pretrainedmodels->cnn_finetune)\n",
            "  Downloading https://files.pythonhosted.org/packages/68/f4/260ec98ea840757a0da09e0ed8135333d59b8dfebe9752a365b04857660a/munch-2.3.2.tar.gz\n",
            "Building wheels for collected packages: cnn-finetune, pretrainedmodels, munch\n",
            "  Running setup.py bdist_wheel for cnn-finetune ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/5b/cf/68/e5add4bdc799cc61ea287974d0ac275dc2275fe9934463fdab\n",
            "  Running setup.py bdist_wheel for pretrainedmodels ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n",
            "  Running setup.py bdist_wheel for munch ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/db/bf/bc/06a3e1bfe0ab27d2e720ceb3cff3159398d92644c0cec2c125\n",
            "Successfully built cnn-finetune pretrainedmodels munch\n",
            "Installing collected packages: munch, pretrainedmodels, cnn-finetune\n",
            "Successfully installed cnn-finetune-0.5.1 munch-2.3.2 pretrainedmodels-0.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-uWY-vOYSWID",
        "colab_type": "code",
        "outputId": "2792f026-0d4e-4b46-b80c-1ae39d2796fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rwARmJBme0nR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract_data(x_data_filepath, y_data_filepath):\n",
        "    X = np.load(x_data_filepath)\n",
        "    y = np.load(y_data_filepath)\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_gHKykv384xe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# Extracting and loading data\n",
        "############################################################\n",
        "class Dataset(Dataset):\n",
        "    \"\"\"CIFAR-10 image dataset.\"\"\"\n",
        "    def __init__(self, data_path, excel_file_path, transformations=None, normalize=True):\n",
        "        \n",
        "        # self.image_names = []\n",
        "        \n",
        "        self.len = len(image_names) \n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        for each color:\n",
        "          file_path = image_name + color\n",
        "          image = np(file_path)\n",
        "          \n",
        "        \n",
        "        return self.x_data[idx], self.y_data[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUzoAdc4djZ_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# Convolutional Neural Network\n",
        "############################################################\n",
        "class ConvolutionalNN(nn.Module):\n",
        "    \"\"\" \n",
        "        (1) Use self.conv1 as the variable name for your first convolutional layer\n",
        "        (2) Use self.pool as the variable name for your pooling layer\n",
        "        (3) User self.conv2 as the variable name for your second convolutional layer\n",
        "        (4) Use self.fc1 as the variable name for your first fully connected layer\n",
        "        (5) Use self.fc2 as the variable name for your second fully connected layer\n",
        "        (6) Use self.fc3 as the variable name for your third fully connected layer\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \n",
        "        super(ConvolutionalNN, self).__init__()\n",
        "        \n",
        "        # Conv2D: (input channels, output channels, filter size, stride, padding)\n",
        "        self.conv1 = nn.Conv2d(3, 7, 3, 1, 0) \n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(7, 16, 3, 1, 0) \n",
        "\n",
        "        self.fc1 = nn.Linear(16*13*13, 130) \n",
        "        self.fc2 = nn.Linear(130, 72) \n",
        "        self.fc3 = nn.Linear(72, 10) \n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # tensor size (x, y, z, z) <- x: batch size, y: number of channels, z: dimension of each channel\n",
        "        \n",
        "        # out = (64, 7, 30, 30) <- 32x32 input with 3x3 filter: 30x30 output (32-(3-1)=30)  \n",
        "        out = F.relu(self.conv1(x))\n",
        "        \n",
        "        # out = (64, 7, 15, 15) <- 30x30 input with 2x2 filter: 15x15 output (30/2=15)\n",
        "        out = self.pool(out)\n",
        "        \n",
        "        # out = (64, 16, 13, 13) <- 13x13 input with 3x3 filter: 13x13 output (15-(3-1)=13)  \n",
        "        out = F.relu(self.conv2(out))\n",
        "\n",
        "        # 3 fully connected layers (16x13x13 -> 130 -> 72 -> 10)\n",
        "        out = out.view(out.size(0), -1) # flatten each example: out = (64, \") <- batch_size x (16x13x13)\n",
        "        out = F.sigmoid(self.fc1(out))\n",
        "        out = F.sigmoid(self.fc2(out)) \n",
        "        out = F.sigmoid(self.fc3(out))\n",
        "        \n",
        "        return out\n",
        "    \n",
        "    \"\"\" \n",
        "        Please do not change the functions below. \n",
        "        They will be used to test the correctness of your implementation \n",
        "    \"\"\"\n",
        "    def get_conv1_params(self):\n",
        "        return self.conv1.__repr__()\n",
        "    \n",
        "    def get_pool_params(self):\n",
        "        return self.pool.__repr__()\n",
        "\n",
        "    def get_conv2_params(self):\n",
        "        return self.conv2.__repr__()\n",
        "    \n",
        "    def get_fc1_params(self):\n",
        "        return self.fc1.__repr__()\n",
        "    \n",
        "    def get_fc2_params(self):\n",
        "        return self.fc2.__repr__()\n",
        "    \n",
        "    def get_fc3_params(self):\n",
        "        return self.fc3.__repr__()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "paHtQfk8XFaF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def AdvancedCNN(model,num_classes=27,input_size=(512,512)):\n",
        "    CNN_model = make_model(model, num_classes=num_classes, pretrained=True, input_size=input_size)\n",
        "    \n",
        "    return CNN_model\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yc0sIBiYdzFd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "############################################################\n",
        "# Run Experiment\n",
        "############################################################\n",
        "def run_experiment(neural_network, train_loader, test_loader, loss_function, optimizer):\n",
        "    \"\"\"\n",
        "    Runs experiment on the model neural network given a train and test data loader, loss function and optimizer.\n",
        "\n",
        "    Args:\n",
        "        neural_network (NN model that extends torch.nn.Module): For example, it should take an instance of either\n",
        "                                                                FeedForwardNN or ConvolutionalNN,\n",
        "        train_loader (DataLoader),\n",
        "        test_loader (DataLoader),\n",
        "        loss_function (torch.nn.CrossEntropyLoss),\n",
        "        optimizer (optim.SGD)\n",
        "    Returns:\n",
        "        tuple: First position, testing accuracy.\n",
        "               Second position, training accuracy.\n",
        "               Third position, training loss.\n",
        "\n",
        "               For example, if you find that\n",
        "                            testing accuracy = 0.76,\n",
        "                            training accuracy = 0.24\n",
        "                            training loss = 0.56\n",
        "\n",
        "               This function should return (0.76, 0.24, 0.56)\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "       neural_network.cuda()\n",
        "    \n",
        "    max_epochs = 100\n",
        "    train_loss = np.zeros((max_epochs))\n",
        "    train_accuracy = np.zeros((max_epochs))\n",
        "    test_accuracy = np.zeros((max_epochs))\n",
        "    \n",
        "    # optimize weights\n",
        "    for epoch in range(max_epochs):\n",
        "    \n",
        "        print('Training neural network...')\n",
        "        for i, data in enumerate(train_loader, 0):            \n",
        "            train_batch_NN(data, neural_network, loss_function, optimizer) # train on batch\n",
        "\n",
        "        print('Calculating Statistics over Epochs:')\n",
        "        # get training loss and accuracy for this epoch  \n",
        "        train_loss[epoch], train_accuracy[epoch] = get_train_statistics(train_loader, neural_network, loss_function)\n",
        "        test_accuracy[epoch] = get_test_statistics(test_loader, neural_network)\n",
        "        print(\"epoch:\", epoch, \"loss:\", train_loss[epoch], \"train accuracy:\", train_accuracy[epoch], \"test accuracy:\", \n",
        "              test_accuracy[epoch])\n",
        "        \n",
        "    return (train_loss, train_accuracy, test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MYaxaZWresbx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize_image(image):\n",
        "    \"\"\"\n",
        "    Normalizes the RGB pixel values of an image.\n",
        "\n",
        "    Args:\n",
        "        image (3D NumPy array): For example, it should take in a single 3x32x32 image from the CIFAR-10 dataset\n",
        "    Returns:\n",
        "        tuple: The normalized image\n",
        "    \"\"\"\n",
        "    mean = np.mean(image, axis=(1,2))\n",
        "    std = np.std(image, axis=(1,2))\n",
        "    normalized_image = ((image[0,:,:] - mean[0]) / std[0], \n",
        "                        (image[1,:,:] - mean[1]) / std[1], \n",
        "                        (image[2,:,:] - mean[2]) / std[2])\n",
        "    return np.stack(normalized_image, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M6T8PTvWe8uy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# REQUIRED METHOD - Function to train a single batch in the NN (used in run_experiment())\n",
        "\n",
        "def train_batch_NN(data, neural_network, loss_function, optimizer):\n",
        "\n",
        "    # Get inputs and labels from data loader \n",
        "    inputs, labels = data\n",
        "\n",
        "    #print(inputs.size())\n",
        "    inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      inputs.cuda()\n",
        "      labels.cuda()\n",
        "\n",
        "\n",
        "    # Feed the input data into the network \n",
        "    y_pred = neural_network(inputs)\n",
        "\n",
        "\n",
        "    # Calculate the loss using predicted labels and ground truth labels\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss = loss_function(y_pred, labels)\n",
        "\n",
        "\n",
        "    # backpropogates to compute gradient\n",
        "    loss.backward()\n",
        "\n",
        "    # updates the weghts\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2yrc0ynafCIv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# REQUIRED METHOD - Function to get loss and accuracy across all training examples in the NN (used in run_experiment())\n",
        "\n",
        "def get_train_statistics(train_loader, neural_network, loss_function):\n",
        "    \n",
        "    correct = 0\n",
        "    sum_loss = 0\n",
        "    \n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "          \n",
        "            # Get inputs and labels from data loader \n",
        "            inputs, labels = data\n",
        "            \n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "            \n",
        "            if torch.cuda.is_available():\n",
        "              inputs.cuda()\n",
        "              labels.cuda()\n",
        "            \n",
        "        \n",
        "            # Feed the input data into the network \n",
        "            y_pred = neural_network(inputs)\n",
        "            \n",
        "            # Calculate the loss using predicted labels and ground truth labels\n",
        "            loss = loss_function(y_pred, labels)\n",
        "\n",
        "            \n",
        "            # convert predicted labels into numpy\n",
        "            nploss= loss.cpu().data.numpy()\n",
        "            sum_loss = sum_loss + nploss\n",
        "            \n",
        "            \n",
        "            y_pred_np = y_pred.cpu().data.numpy()\n",
        "            label_np = labels.cpu().data.numpy().reshape(len(labels),1)\n",
        "            \n",
        "              \n",
        "            pred_np = np.argmax(y_pred_np, axis=1)\n",
        "            \n",
        "            for j in range(y_pred_np.shape[0]):\n",
        "                if pred_np[j] == label_np[j]:\n",
        "                    correct += 1\n",
        "    \n",
        "    # calculate the accuracy across batches\n",
        "    train_accuracy = float(correct)/float(len(train_loader.dataset))\n",
        "    \n",
        "    return sum_loss, train_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ULpwmUC4fFfE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# REQUIRED METHOD - Function to accuracy across all test examples in the NN (used in run_experiment())\n",
        "\n",
        "def get_test_statistics(test_loader, neural_network):\n",
        "    \n",
        "    correct_test = 0\n",
        "    \n",
        "    for i, data in enumerate(test_loader, 0):\n",
        "\n",
        "            # Get inputs and labels from data loader \n",
        "            inputs, labels = data\n",
        "\n",
        "            #print(inputs.size())\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "            \n",
        "            if torch.cuda.is_available():\n",
        "              inputs.cuda()\n",
        "              labels.cuda()\n",
        "\n",
        "\n",
        "            # Feed the input data into the network \n",
        "            y_pred_test = neural_network(inputs)\n",
        "\n",
        "\n",
        "            # convert predicted laels into numpy\n",
        "            y_pred_np_test = y_pred_test.cpu().data.numpy()\n",
        "            label_np_test = labels.cpu().data.numpy().reshape(len(labels),1)\n",
        "           \n",
        "          \n",
        "            # calculate the training accuracy of the current model\n",
        "            pred_np_test = np.argmax(y_pred_np_test, axis=1)\n",
        "\n",
        "\n",
        "            for j in range(y_pred_np_test.shape[0]):\n",
        "                if pred_np_test[j] == label_np_test[j]:\n",
        "                    correct_test += 1\n",
        "    \n",
        "    # calculate the accuracy across batches\n",
        "    test_accuracy = float(total_correct) / float(len(test_loader.dataset))\n",
        "    \n",
        "    return test_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BbMZi746fIeA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function to plot the loss and training accuracy over epochs\n",
        "\n",
        "def plot_epoch_stats(loss, train_accuracy, test_accuracy):\n",
        "    \n",
        "    max_epochs = 100\n",
        "    print(\"final training accuracy: \", train_accuracy[max_epochs-1])\n",
        "    print(\"final test accuracy: \", test_accuracy[max_epochs-1])\n",
        "    epoch_number = np.arange(0,max_epochs,1)\n",
        "\n",
        "    # Plot the loss over epoch\n",
        "    plt.figure()\n",
        "    plt.plot(epoch_number, loss)\n",
        "    plt.title('Total Loss over Epochs')\n",
        "    plt.xlabel('Number of Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    # Plot the training accuracy over epoch\n",
        "    plt.figure()\n",
        "    plt.plot(epoch_number, train_accuracy)\n",
        "    plt.title('Training Accuracy over Epochs')\n",
        "    plt.xlabel('Number of Epochs')\n",
        "    plt.ylabel('accuracy')\n",
        "    \n",
        "    # Plot the testing accuracy over epoch\n",
        "    plt.figure()\n",
        "    plt.plot(epoch_number, test_accuracy)\n",
        "    plt.title('Testing Accuracy over Epochs')\n",
        "    plt.xlabel('Number of Epochs')\n",
        "    plt.ylabel('accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6upZfsfHfY6S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# RUN CODE BELOW HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "33qJ3E7Or5Tc",
        "colab_type": "code",
        "outputId": "581aaead-4b92-499c-fc23-04085ef0523c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "label_dict = {\n",
        "    0:  \"Nucleoplasm\",  \n",
        "    1:  \"Nuclear membrane\",   \n",
        "    2:  \"Nucleoli\",   \n",
        "    3:  \"Nucleoli fibrillar center\",   \n",
        "    4:  \"Nuclear speckles\",\n",
        "    5:  \"Nuclear bodies\",   \n",
        "    6:  \"Endoplasmic reticulum\",   \n",
        "    7:  \"Golgi apparatus\",   \n",
        "    8:  \"Peroxisomes\",   \n",
        "    9:  \"Endosomes\",   \n",
        "    10:  \"Lysosomes\",   \n",
        "    11:  \"Intermediate filaments\",   \n",
        "    12:  \"Actin filaments\",   \n",
        "    13:  \"Focal adhesion sites\",   \n",
        "    14:  \"Microtubules\",   \n",
        "    15:  \"Microtubule ends\",   \n",
        "    16:  \"Cytokinetic bridge\",   \n",
        "    17:  \"Mitotic spindle\",   \n",
        "    18:  \"Microtubule organizing center\",   \n",
        "    19:  \"Centrosome\",   \n",
        "    20:  \"Lipid droplets\",   \n",
        "    21:  \"Plasma membrane\",   \n",
        "    22:  \"Cell junctions\",   \n",
        "    23:  \"Mitochondria\",   \n",
        "    24:  \"Aggresome\",   \n",
        "    25:  \"Cytosol\",   \n",
        "    26:  \"Cytoplasmic bodies\",   \n",
        "    27:  \"Rods & rings\"\n",
        "}\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "train_labels_file_path = '/content/gdrive/My Drive/Colab Notebooks/train.csv'\n",
        "\n",
        "with open(train_labels_file_path) as train_labels_file:\n",
        "    labels_df = pd.read_csv(train_labels_file)\n",
        "    \n",
        "print(labels_df)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-83c132dc842a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mtrain_labels_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/My Drive/Colab Notebooks/train.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels_file_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrain_labels_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mlabels_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/Colab Notebooks/train.csv'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "GlGMmUOBfdwt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialize constants\n",
        "'''\n",
        "train_images_file_path = '/content/gdrive/My Drive/Colab Notebooks/train'\n",
        "test_images_file_path = '/content/gdrive/My Drive/Colab Notebooks/test'\n",
        "test_labels_file_path = '/content/gdrive/My Drive/Colab Notebooks/cifar10-data/test_labels.npy'\n",
        "\n",
        "# create train and test data loaders\n",
        "X_train, y_train = extract_data('gdrive/My Drive/?.npy', 'gdrive/My Drive/?.npy') # ? examples ################################ GPU\n",
        "X_test, y_test = extract_data('gdrive/My Drive/?.npy', 'gdrive/My Drive/?.npy') # ? examples ################################ GPU\n",
        "'''\n",
        "# specify the loss function\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "if torch.cuda.is_available():\n",
        "   loss_function.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qbwVA0iWcWvU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#test\n",
        "x_train = 'drive/My Drive/COLAB/CIS 519/HW3/cifar10-data/train_images.npy'\n",
        "y_train = 'drive/My Drive/COLAB/CIS 519/HW3/cifar10-data/train_labels.npy'\n",
        "X_train,y_train = extract_data(x_train,y_train)\n",
        "\n",
        "\n",
        "  \n",
        "x_test = 'drive/My Drive/COLAB/CIS 519/HW3/cifar10-data/test_images.npy'\n",
        "y_test= 'drive/My Drive/COLAB/CIS 519/HW3/cifar10-data/test_labels.npy'\n",
        "X_test, y_test = extract_data(x_test,y_test)\n",
        "\n",
        "train_dataset = Dataset(X_train, y_train, normalize=False)\n",
        "test_dataset = Dataset(X_test, y_test, normalize=False)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LQBFjTeEfveA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run Experiment and save results\n",
        "\n",
        "train_dataset = Dataset(X_train, y_train, normalize=False)\n",
        "test_dataset = Dataset(X_test, y_test, normalize=False)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "conv_raw_net = ConvolutionalNN() # create the NN\n",
        "optimizer = optim.SGD(conv_raw_net.parameters(), lr=0.001, momentum=0.9) # specify the optimizer\n",
        "(loss, train_accuracy, test_accuracy) = run_experiment(conv_raw_net, train_loader, test_loader, loss_function, optimizer)\n",
        "\n",
        "# np.save(\"gdrive/My Drive/statistics/conv_loss.npy\", loss)\n",
        "# np.save(\"gdrive/My Drive/statistics/conv_train_accuracy.npy\", train_accuracy)\n",
        "# np.save(\"gdrive/My Drive/statistics/conv_test_accuracy.npy\", test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nQtZjyOqYtbo",
        "colab_type": "code",
        "outputId": "e16b08e5-0ac6-40c8-d0a2-9728590ad748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1951
        }
      },
      "cell_type": "code",
      "source": [
        "# Run Experiment on Advanced CNN:\n",
        "\n",
        "# get the name of model here https://pypi.org/project/cnn-finetune/\n",
        "\n",
        "name = 'resnet18'\n",
        "CNN_Model = AdvancedCNN(name)\n",
        "optimizer = optim.SGD(CNN_Model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "(loss, train_accuracy, test_accuracy) = run_experiment(CNN_Model, train_loader, test_loader, loss_function, optimizer)\n",
        "plot_epoch_stats(loss, train_accuracy, test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training neural network...\n",
            "Calculating Statistics over Epochs:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-d05eb4b39a4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNN_Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNN_Model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplot_epoch_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-f363e50e2d9b>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(neural_network, train_loader, test_loader, loss_function, optimizer)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calculating Statistics over Epochs:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# get training loss and accuracy for this epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         print(\"epoch:\", epoch, \"loss:\", train_loss[epoch], \"train accuracy:\", train_accuracy[epoch], \"test accuracy:\", \n",
            "\u001b[0;32m<ipython-input-10-37588a4e3d5d>\u001b[0m in \u001b[0;36mget_train_statistics\u001b[0;34m(train_loader, neural_network, loss_function)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Feed the input data into the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# Calculate the loss using predicted labels and ground truth labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/cnn_finetune/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/cnn_finetune/base.py\u001b[0m in \u001b[0;36mfeatures\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1252\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1253\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m     )\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}