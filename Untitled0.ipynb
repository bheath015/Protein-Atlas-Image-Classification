{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bheath015/Protein-Atlas-Image-Classification/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "LumfhCpiew11",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# Imports\n",
        "############################################################\n",
        "# Include your imports here, if any are used.\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rwARmJBme0nR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract_data(x_data_filepath, y_data_filepath):\n",
        "    X = np.load(x_data_filepath)\n",
        "    y = np.load(y_data_filepath)\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUzoAdc4djZ_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# Convolutional Neural Network\n",
        "############################################################\n",
        "class ConvolutionalNN(nn.Module):\n",
        "    \"\"\" \n",
        "        (1) Use self.conv1 as the variable name for your first convolutional layer\n",
        "        (2) Use self.pool as the variable name for your pooling layer\n",
        "        (3) User self.conv2 as the variable name for your second convolutional layer\n",
        "        (4) Use self.fc1 as the variable name for your first fully connected layer\n",
        "        (5) Use self.fc2 as the variable name for your second fully connected layer\n",
        "        (6) Use self.fc3 as the variable name for your third fully connected layer\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \n",
        "        super(ConvolutionalNN, self).__init__()\n",
        "        \n",
        "        # Conv2D: (input channels, output channels, filter size, stride, padding)\n",
        "        self.conv1 = nn.Conv2d(3, 7, 3, 1, 0) \n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(7, 16, 3, 1, 0) \n",
        "\n",
        "        self.fc1 = nn.Linear(16*13*13, 130) \n",
        "        self.fc2 = nn.Linear(130, 72) \n",
        "        self.fc3 = nn.Linear(72, 10) \n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # tensor size (x, y, z, z) <- x: batch size, y: number of channels, z: dimension of each channel\n",
        "        \n",
        "        # out = (64, 7, 30, 30) <- 32x32 input with 3x3 filter: 30x30 output (32-(3-1)=30)  \n",
        "        out = F.relu(self.conv1(x))\n",
        "        \n",
        "        # out = (64, 7, 15, 15) <- 30x30 input with 2x2 filter: 15x15 output (30/2=15)\n",
        "        out = self.pool(out)\n",
        "        \n",
        "        # out = (64, 16, 13, 13) <- 13x13 input with 3x3 filter: 13x13 output (15-(3-1)=13)  \n",
        "        out = F.relu(self.conv2(out))\n",
        "\n",
        "        # 3 fully connected layers (16x13x13 -> 130 -> 72 -> 10)\n",
        "        out = out.view(out.size(0), -1) # flatten each example: out = (64, \") <- batch_size x (16x13x13)\n",
        "        out = F.sigmoid(self.fc1(out))\n",
        "        out = F.sigmoid(self.fc2(out)) \n",
        "        out = F.sigmoid(self.fc3(out))\n",
        "        \n",
        "        return out\n",
        "    \n",
        "    \"\"\" \n",
        "        Please do not change the functions below. \n",
        "        They will be used to test the correctness of your implementation \n",
        "    \"\"\"\n",
        "    def get_conv1_params(self):\n",
        "        return self.conv1.__repr__()\n",
        "    \n",
        "    def get_pool_params(self):\n",
        "        return self.pool.__repr__()\n",
        "\n",
        "    def get_conv2_params(self):\n",
        "        return self.conv2.__repr__()\n",
        "    \n",
        "    def get_fc1_params(self):\n",
        "        return self.fc1.__repr__()\n",
        "    \n",
        "    def get_fc2_params(self):\n",
        "        return self.fc2.__repr__()\n",
        "    \n",
        "    def get_fc3_params(self):\n",
        "        return self.fc3.__repr__()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yc0sIBiYdzFd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# Run Experiment\n",
        "############################################################\n",
        "def run_experiment(neural_network, train_loader, test_loader, loss_function, optimizer):\n",
        "    \"\"\"\n",
        "    Runs experiment on the model neural network given a train and test data loader, loss function and optimizer.\n",
        "\n",
        "    Args:\n",
        "        neural_network (NN model that extends torch.nn.Module): For example, it should take an instance of either\n",
        "                                                                FeedForwardNN or ConvolutionalNN,\n",
        "        train_loader (DataLoader),\n",
        "        test_loader (DataLoader),\n",
        "        loss_function (torch.nn.CrossEntropyLoss),\n",
        "        optimizer (optim.SGD)\n",
        "    Returns:\n",
        "        tuple: First position, testing accuracy.\n",
        "               Second position, training accuracy.\n",
        "               Third position, training loss.\n",
        "\n",
        "               For example, if you find that\n",
        "                            testing accuracy = 0.76,\n",
        "                            training accuracy = 0.24\n",
        "                            training loss = 0.56\n",
        "\n",
        "               This function should return (0.76, 0.24, 0.56)\n",
        "    \"\"\"\n",
        "\n",
        "    neural_network.cuda()\n",
        "    \n",
        "    max_epochs = 100\n",
        "    train_loss = np.zeros((max_epochs))\n",
        "    train_accuracy = np.zeros((max_epochs))\n",
        "    test_accuracy = np.zeros((max_epochs))\n",
        "    \n",
        "    # optimize weights\n",
        "    for epoch in range(max_epochs):\n",
        "    \n",
        "        print('Training neural network...')\n",
        "        for i, data in enumerate(train_loader, 0):            \n",
        "            train_batch_NN(data, neural_network, loss_function, optimizer) # train on batch\n",
        "\n",
        "        print('Calculating Statistics over Epochs:')\n",
        "        # get training loss and accuracy for this epoch  \n",
        "        train_loss[epoch], train_accuracy[epoch] = get_train_statistics(train_loader, neural_network, loss_function)\n",
        "        test_accuracy[epoch] = get_test_statistics(test_loader, neural_network)\n",
        "        print(\"epoch:\", epoch, \"loss:\", train_loss[epoch], \"train accuracy:\", train_accuracy[epoch], \"test accuracy:\", \n",
        "              test_accuracy[epoch])\n",
        "        \n",
        "    return (train_loss, train_accuracy, test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MYaxaZWresbx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize_image(image):\n",
        "    \"\"\"\n",
        "    Normalizes the RGB pixel values of an image.\n",
        "\n",
        "    Args:\n",
        "        image (3D NumPy array): For example, it should take in a single 3x32x32 image from the CIFAR-10 dataset\n",
        "    Returns:\n",
        "        tuple: The normalized image\n",
        "    \"\"\"\n",
        "    mean = np.mean(image, axis=(1,2))\n",
        "    std = np.std(image, axis=(1,2))\n",
        "    normalized_image = ((image[0,:,:] - mean[0]) / std[0], \n",
        "                        (image[1,:,:] - mean[1]) / std[1], \n",
        "                        (image[2,:,:] - mean[2]) / std[2])\n",
        "    return np.stack(normalized_image, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M6T8PTvWe8uy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}